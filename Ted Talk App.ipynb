{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da717865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1.tar.gz (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (1.20.1)\n",
      "Requirement already satisfied: pillow in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (8.2.0)\n",
      "Requirement already satisfied: matplotlib in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (4.29.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (20.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: six in /Users/vaishakkallampad/opt/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.15.0)\n",
      "Building wheels for collected packages: wordcloud\n",
      "  Building wheel for wordcloud (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wordcloud: filename=wordcloud-1.8.1-cp38-cp38-macosx_10_9_x86_64.whl size=158478 sha256=aab320b1b573bc457c7de2c7d9e259bb74b74cb3b18fd45f6511dd72df9a2ec9\n",
      "  Stored in directory: /Users/vaishakkallampad/Library/Caches/pip/wheels/4d/3f/0d/a2ba9b7895c9f1be89018b3141c3df3d4f9c786c882ccfbc3b\n",
      "Successfully built wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a894e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.11.0\n",
      "  latest version: 4.12.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/vaishakkallampad/opt/anaconda3/envs/tensorflow\n",
      "\n",
      "  added / updated specs:\n",
      "    - wordcloud=1.8.1\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.5.18  |       h033912b_0         144 KB  conda-forge\n",
      "    certifi-2022.5.18          |   py38h50d1736_0         150 KB  conda-forge\n",
      "    openssl-1.1.1o             |       hfe4f2af_0         1.9 MB  conda-forge\n",
      "    python_abi-3.8             |           2_cp38           4 KB  conda-forge\n",
      "    wordcloud-1.8.1            |   py38h96a0964_2         171 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  python_abi         conda-forge/osx-64::python_abi-3.8-2_cp38\n",
      "  wordcloud          conda-forge/osx-64::wordcloud-1.8.1-py38h96a0964_2\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.10.26~ --> conda-forge::ca-certificates-2022.5.18-h033912b_0\n",
      "  certifi            pkgs/main::certifi-2021.10.8-py38hecd~ --> conda-forge::certifi-2022.5.18-py38h50d1736_0\n",
      "  openssl              pkgs/main::openssl-1.1.1l-h9ed2024_0 --> conda-forge::openssl-1.1.1o-hfe4f2af_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "wordcloud-1.8.1      | 171 KB    | ##################################### | 100% \n",
      "certifi-2022.5.18    | 150 KB    | ##################################### | 100% \n",
      "openssl-1.1.1o       | 1.9 MB    | ##################################### | 100% \n",
      "python_abi-3.8       | 4 KB      | ##################################### | 100% \n",
      "ca-certificates-2022 | 144 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge wordcloud=1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad9dfdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from wordcloud import WordCloud\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "64540292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TedTalk:\n",
    "    def __init__(self):\n",
    "        self.speaker_data = pd.read_csv('dataset/speaker_data.csv')\n",
    "        self.talk_data = pd.read_csv('dataset/talk_data.csv')\n",
    "        self.transcript_data = pd.read_csv('dataset/transcript_data.csv')\n",
    "        self.preprocessed_data = self.preprocessing()\n",
    "        self.themes_df = pd.DataFrame()\n",
    "#         self.recommendation_df = self.recommendations()\n",
    "        \n",
    "    def preprocessing(self):\n",
    "        # filling 648 'speaker_occ'=Nan with value 'Unknown'\n",
    "        self.speaker_data['speaker_occ'] = self.speaker_data['speaker_occ'].fillna('Unknown')\n",
    "        #filling 623 'speaker_bio'=Nan with value 'Unknown'\n",
    "        self.speaker_data['speaker_bio'] = self.speaker_data['speaker_bio'].fillna('Unknown')\n",
    "        \n",
    "        self.speaker_data['speaker'] = self.speaker_data['speaker'].fillna('Unknown')\n",
    "        #dropping the 'speaker_title' since majority is Nan and it does not provide any useful insight for our use case\n",
    "        self.speaker_data = self.speaker_data.drop(columns=['speaker_title'])\n",
    "        \n",
    "        self.transcript_data = self.transcript_data.dropna(subset=['transcript'])\n",
    "        \n",
    "        final_df = pd.merge(self.speaker_data, self.talk_data, how='inner', left_on = 'talk', right_on = 'talk_name')\n",
    "        #Dropping the duplicate column 'talk_name'\n",
    "        final_df = final_df.drop(columns=['talk_name'])\n",
    "        final_df = pd.merge(final_df, self.transcript_data, how='inner', left_on = 'talk', right_on = 'title')\n",
    "        \n",
    "        final_df = final_df.drop(columns=['title'])\n",
    "        #Removing all rows which have duplicated talk name\n",
    "        final_df = final_df.drop_duplicates(subset=['talk'])\n",
    "        final_df = final_df.reset_index()\n",
    "        \n",
    "        Text=final_df['transcript'].tolist()\n",
    "        tfidf=text.TfidfVectorizer(input=Text,stop_words=\"english\")\n",
    "        matrix=tfidf.fit_transform(Text)\n",
    "        sim_unigram=cosine_similarity(matrix)\n",
    "        def get_similar_articles(x):\n",
    "            return \"-,\".join((final_df['talk']).loc[x.argsort()[-6:-1]])\n",
    "        final_df['most_similar_transcript_unigrams']=[get_similar_articles(x) for x in sim_unigram]\n",
    "#         final_df.to_csv('clean_data.csv',index=False)\n",
    "        return final_df\n",
    "    \n",
    "    def statistics(self):\n",
    "        print(\"\\nHere are few interesting insights for you\")\n",
    "        self.videos_per_year_graph()\n",
    "        self.get_pop_theme_graph()\n",
    "        self.top_speaker()\n",
    "        self.most_famous_talks()\n",
    "        self.top_events()\n",
    "        \n",
    "        \n",
    "    def videos_per_year_graph(self):\n",
    "        df = self.preprocessed_data.copy(deep=True)\n",
    "        # convert the recorded_at  Date to datetime\n",
    "        df['recorded_at'] = pd.to_datetime(df['recorded_at'])\n",
    "        # add a column for Year\n",
    "        df['Year'] = df['recorded_at'].dt.year\n",
    "        # print the dataframe\n",
    "        df['year'] = pd.to_datetime(df['recorded_at']).dt.year\n",
    "        \n",
    "        fig = plt.figure() \n",
    "        fig.set_size_inches(8,6)\n",
    "        df.Year.value_counts().sort_index().plot()\n",
    "        plt.title(\"Rise in Videos Over the Years\")\n",
    "        plt.xlabel('Years')\n",
    "        plt.ylabel('Number of Videos Released per year')\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    def most_famous_talks(self):\n",
    "        print(\"These are our top 25 videos:\")\n",
    "        famous_talks = self.preprocessed_data.sort_values('views', ascending=False)[:25]\n",
    "        display(famous_talks.iloc[:,[1,2,5,6,7]])\n",
    "        return\n",
    "    \n",
    "    def get_themes(self):\n",
    "        df = self.preprocessed_data.copy(deep=True)\n",
    "        df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x))\n",
    "        s = df.apply(lambda x: pd.Series(x['tags']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "        s.name = 'theme'\n",
    "        self.themes_df = df.join(s)\n",
    "        pop_themes = pd.DataFrame(self.themes_df['theme'].value_counts()).reset_index()\n",
    "        pop_themes.columns = ['theme', 'talks']\n",
    "        top_10 = pop_themes[~((pop_themes['theme']=='TED-Ed') | (pop_themes['theme']=='TEDx'))].iloc[0:10,:]\n",
    "        top_10 = top_10.reset_index(drop=True)\n",
    "        return top_10\n",
    "    \n",
    "    def get_pop_theme_list(self):\n",
    "        top_10 = self.get_themes()\n",
    "        print('\\nHere are few popular talk themes:')\n",
    "        for i in range(len(top_10['theme'])):\n",
    "            print('\\n\\t',i+1,top_10['theme'][i])\n",
    "        return\n",
    "    \n",
    "    def get_pop_theme_graph(self):\n",
    "        top_10 = self.get_themes()\n",
    "        plt.figure(figsize=(15,5))\n",
    "        sns.barplot(x='theme', y='talks', data=top_10.head(10))\n",
    "        plt.title(\"Most popular themes over the years\")\n",
    "        plt.xlabel('Themes')\n",
    "        plt.ylabel('Number of talks')\n",
    "        plt.show()\n",
    "        return\n",
    "        \n",
    "        \n",
    "    def get_top_100_talk_theme(self,theme):\n",
    "        print('\\nHere are the top 100 talk on ',theme)\n",
    "        top100 = self.themes_df[self.themes_df['theme']==theme].sort_values('views', ascending=False)[:50]\n",
    "        display(top100.iloc[:,[1,2,6,7]])\n",
    "        return top100.iloc[:,[1,2,6,7]]\n",
    "    \n",
    "    \n",
    "    def top_speaker(self):\n",
    "        df = self.preprocessed_data.copy(deep=True)\n",
    "        df['speaker_frequency'] = df.groupby('speaker')['speaker'].transform('count')\n",
    "        df['speaker_views'] = df.groupby('speaker')['views'].transform('sum')\n",
    "        df['speaker_avg_views'] =  df[\"speaker_views\"]/df[\"speaker_frequency\"]\n",
    "        df = df.sort_values('speaker_avg_views',ascending=[False])\n",
    "        plt.figure(figsize=(15,5))\n",
    "        sns.barplot(x='speaker', y='speaker_avg_views', data=df.head(20))\n",
    "        plt.title(\"Most Popular Speakers\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel('Popular Speakers')\n",
    "        plt.ylabel('Average Views')\n",
    "        plt.show()\n",
    "        \n",
    "    def top_events(self):\n",
    "        df = self.preprocessed_data.copy(deep=True)\n",
    "        df['event_frequency'] = df.groupby('event')['event'].transform('count')\n",
    "        df['event_views'] = df.groupby('event')['views'].transform('sum')\n",
    "        df['event_avg_views'] =  df[\"event_views\"]/df[\"event_frequency\"]\n",
    "        df = df.sort_values('event_avg_views',ascending=[False])\n",
    "        plt.figure(figsize=(15,5))\n",
    "        sns.barplot(x='event', y='event_avg_views', data=df.head(20))\n",
    "        plt.title(\"Most Popular Ted Events\")\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel('Events')\n",
    "        plt.ylabel('Number of Shows')\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    def talk_details(self,talk_id):\n",
    "#         display(self.preprocessed_data.head(1))\n",
    "#         print(self.preprocessed_data['index'talk_id])\n",
    "#         display(self.preprocessed_data[self.preprocessed_data['index']==talk_id])\n",
    "        if talk_id not in self.preprocessed_data.index:\n",
    "            print(\"Wrong number selected. Please try again\")\n",
    "            return\n",
    "        else:\n",
    "            print('\\n\\033[1mTalk\\033[0m : ',self.preprocessed_data['talk'][talk_id])\n",
    "            print('\\033[1mSpeaker\\033[0m : ',self.preprocessed_data['speaker'][talk_id])\n",
    "            print('\\033[1mSpeaker Occupation\\033[0m : ',self.preprocessed_data['speaker_occ'][talk_id])\n",
    "            print('\\033[1mTalk Description\\033[0m : ',self.preprocessed_data['talk_desc'][talk_id])\n",
    "            print('\\033[1mEvent\\033[0m : ',self.preprocessed_data['event'][talk_id])\n",
    "            print('\\033[1mViews\\033[0m : ',self.preprocessed_data['views'][talk_id])\n",
    "            print('\\033[1mTags\\033[0m : ',self.preprocessed_data['tags'][talk_id])\n",
    "            print('\\n\\n',self.generate_wordcloud(talk_id))\n",
    "            print(\"\\n\\033[1mTranscript\\033[0m: \\n\",self.preprocessed_data['transcript'][talk_id])\n",
    "            print('\\n\\n',self.get_similar5(talk_id))\n",
    "            return\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#     def recommendations(self):\n",
    "#         cleaned_df = pd.read_csv('clean_data.csv')\n",
    "#         Text=cleaned_df['transcript'].tolist()\n",
    "#         tfidf=text.TfidfVectorizer(input=Text,stop_words=\"english\")\n",
    "#         matrix=tfidf.fit_transform(Text)\n",
    "#         sim_unigram=cosine_similarity(matrix)\n",
    "#         def get_similar_articles(x):\n",
    "#             return \",\".join((cleaned_df['talk']).loc[x.argsort()[-6:-1]])\n",
    "#         cleaned_df['most_similar_transcript_unigrams']=[get_similar_articles(x) for x in sim_unigram]\n",
    "#         return cleaned_df\n",
    "    \n",
    "    def get_similar5(self,talk_index):\n",
    "        rec_df = self.preprocessed_data.copy(deep=True)\n",
    "        example_talk = rec_df.iloc[talk_index,1]\n",
    "        example_tags = rec_df.iloc[talk_index,9]\n",
    "        example_recommendations_unigram = rec_df.iloc[talk_index,13].split('-,')\n",
    "        listA = [''.join(c for c in word if c.isalpha()) for word in example_tags.split(',')]\n",
    "        setA = set(listA)\n",
    "        print(\"Recommendations Unigram : \")\n",
    "        myTable = PrettyTable([\"Talk Id.\",\"Recommended Talks(B)\", \"(tagsA & tagsB)/tagsA\", \"(tagsA & tagsB)/tagsB\"])\n",
    "        for each in example_recommendations_unigram[::-1]:\n",
    "            tagsB = rec_df['tags'][rec_df.talk==each].values\n",
    "            listB = [''.join(c for c in word if c.isalpha()) for word in tagsB[0].split(',')]\n",
    "            setB = set(listB)\n",
    "            overlap = setA & setB\n",
    "            universe = setA | setB\n",
    "            result1 = round(float(len(overlap)) / len(setA) * 100,1)\n",
    "            result2 = round(float(len(overlap)) / len(setB) * 100,1)\n",
    "            talkid= rec_df[rec_df.talk==each].index.values\n",
    "            myTable.add_row([talkid,each, result1, result2])\n",
    "        print(myTable)\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_wordcloud(self,talk_index):\n",
    "#         df = self.preprocessed_data.copy(deep=True)\n",
    "        text = self.preprocessed_data['transcript'][talk_index] \n",
    "        wordcloud = WordCloud(collocations = False, background_color = 'white').generate(str(text))\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "27ce3c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ttrs = TedTalk()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14551ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mTED TALK App\u001b[0m\n",
      "\n",
      "Lets see if we can keep you enganged\n",
      "Here are your options:\n",
      "\n",
      "\t1. View overall statistics of the Ted Talks over the years\n",
      "\n",
      "\t2. No stats pls! I want to see some good videos\n",
      "\n",
      "\t3. I want to exit\n",
      "\n",
      "Enter your choice : \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\033[1mTED TALK App\\033[0m\")\n",
    "home =True\n",
    "\n",
    "while home:\n",
    "    print(\"\\nLets see if we can keep you enganged\")\n",
    "    print(\"Here are your options:\")\n",
    "    print(\"\\n\\t1. View overall statistics of the Ted Talks over the years\")\n",
    "    print(\"\\n\\t2. No stats pls! I want to see some good videos\")\n",
    "    print(\"\\n\\t3. I want to exit\")\n",
    "    print(\"\\nEnter your choice : \")\n",
    "    while True:\n",
    "        try:\n",
    "            x = int(input())\n",
    "        except ValueError:\n",
    "            print(\"Expecting a valid input\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    if x==1:\n",
    "        ttrs.statistics()\n",
    "    elif x==2:\n",
    "        top_10_themes = ttrs.get_themes()\n",
    "        checktheme = True\n",
    "        while checktheme:\n",
    "            ttrs.get_pop_theme_list()\n",
    "            print(\"\\nWhich one would you like to checkout. Enter number:\")\n",
    "            theme_choice = input()\n",
    "            sametheme = True\n",
    "            while sametheme:\n",
    "                top100_talks_theme = ttrs.get_top_100_talk_theme(top_10_themes['theme'][int(theme_choice)-1])\n",
    "                print('-->If you want to checkout any of these enter the number you see next the Ted Talk name.', \n",
    "                      '\\n-->If you want to explore some other theme, enter 9999',\n",
    "                      '\\n-->Go back to home page, enter -1 ')\n",
    "                talk_choice = int(input())\n",
    "                if talk_choice==9999:\n",
    "                    sametheme = False\n",
    "                    continue\n",
    "                elif talk_choice==-1:\n",
    "                    home = True\n",
    "                    checktheme = False\n",
    "                    sametheme = False\n",
    "                    continue\n",
    "                else :\n",
    "                    ttrs.talk_details(talk_choice)\n",
    "                    print('-->If you want to checkout ted talks under the same theme enter 0', \n",
    "                          '\\n-->Go back to home page, enter -1')\n",
    "                    y = int(input())\n",
    "                    if y==-1:\n",
    "                        sametheme = False\n",
    "                        checktheme = False\n",
    "                        continue\n",
    "    elif x==3:\n",
    "        home=False\n",
    "        break\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea3bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e937fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5 
}
