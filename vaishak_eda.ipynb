{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8895bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data = pd.read_csv('dataset/speaker_data.csv')\n",
    "talk_data = pd.read_csv('dataset/talk_data.csv')\n",
    "transcript_data = pd.read_csv('dataset/transcript_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5495e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e36e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e904c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b3296",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data = speaker_data.dropna(subset=['talk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089fbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7956b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling 648 'speaker_occ'=Nan with value 'Unknown'\n",
    "speaker_data['speaker_occ'] = speaker_data['speaker_occ'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e26e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling 623 'speaker_bio'=Nan with value 'Unknown'\n",
    "speaker_data['speaker_bio'] = speaker_data['speaker_bio'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afa661",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb96bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data['speaker'] = speaker_data['speaker'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the 'speaker_title' since majority is Nan and it does not provide any useful insight for our use case\n",
    "speaker_data = speaker_data.drop(columns=['speaker_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bdf183",
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2bcf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5146c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data = transcript_data.dropna(subset=['transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "talk_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8c217",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(speaker_data, talk_data, how='inner', left_on = 'talk', right_on = 'talk_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a439993",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe49041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the duplicate column 'talk_name'\n",
    "final_df = final_df.drop(columns=['talk_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea39571",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899b3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(final_df, transcript_data, how='inner', left_on = 'talk', right_on = 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop(columns=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51458cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all rows which have duplicated talk name\n",
    "final_df = final_df.drop_duplicates(subset=['talk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb14d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2da36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('cleaned data/vaishak_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.iloc[3][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b603a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46e1687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4016, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec2d8d2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9eefc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4016, 68448)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa11796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(input=['Baking apple pie? Discount orange warehouse has you '\n",
       "                       'covered! A fruit’s a fruit, right?It’s 1988, and '\n",
       "                       'scientist James Hansen  has just testified to the '\n",
       "                       'United States Congress  that global warming trends are '\n",
       "                       'caused by human activity, and will pose an increasing '\n",
       "                       'threat  to humanity in the future.Well, well.  That’s '\n",
       "                       'unusually prescient for a human.Looking for a wedding '\n",
       "                       'dress...\n",
       "                       'mind has changed over the years and grown because of '\n",
       "                       'the people in my life who planted seeds in me, some '\n",
       "                       \"that I saw and some that I didn't. So wouldn't it be \"\n",
       "                       'great if instead of having a cancel culture we create '\n",
       "                       'a compassion culture where we are willing to suffer '\n",
       "                       'alongside the ones we love, because we love them. And '\n",
       "                       \"can't we become a community that plants seeds? After \"\n",
       "                       \"all, if we don't, who will?Thank you.\", ...],\n",
       "                stop_words='english')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "144915dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4016x68448 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1695421 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ec53e74",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed064900",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4016, 4016)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a7e88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3d6249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>talk</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_occ</th>\n",
       "      <th>speaker_bio</th>\n",
       "      <th>talk_desc</th>\n",
       "      <th>event</th>\n",
       "      <th>views</th>\n",
       "      <th>duration</th>\n",
       "      <th>tags</th>\n",
       "      <th>recorded_at</th>\n",
       "      <th>published on</th>\n",
       "      <th>transcript</th>\n",
       "      <th>most_similar_talks_unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you outsmart the apples and oranges fallacy?</td>\n",
       "      <td>Elizabeth Cox</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>It's 1997. The United States Senate has called...</td>\n",
       "      <td>TED-Ed</td>\n",
       "      <td>119359</td>\n",
       "      <td>327</td>\n",
       "      <td>['education', 'psychology', 'animation', 'TED-...</td>\n",
       "      <td>2021-04-05T00:00:00.000+00:00</td>\n",
       "      <td>1617636753</td>\n",
       "      <td>Baking apple pie? Discount orange warehouse ha...</td>\n",
       "      <td>100 solutions to reverse global warming,How we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The exploitation of US college athletes</td>\n",
       "      <td>Tim Nevius</td>\n",
       "      <td>College sports lawyer</td>\n",
       "      <td>Tim Nevius is a leading sports lawyer and coll...</td>\n",
       "      <td>Colleges and universities in the US make billi...</td>\n",
       "      <td>TEDxDayton</td>\n",
       "      <td>438573</td>\n",
       "      <td>611</td>\n",
       "      <td>['sports', 'law', 'education', 'United States'...</td>\n",
       "      <td>2020-11-10T00:00:00.000+00:00</td>\n",
       "      <td>1617634131</td>\n",
       "      <td>In college sports, American universities are e...</td>\n",
       "      <td>Protecting the brain against concussion,A summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does ultrasound work?</td>\n",
       "      <td>Jacques Abramowicz</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In a dark cave, bats can't see much. But even ...</td>\n",
       "      <td>TED-Ed</td>\n",
       "      <td>140874</td>\n",
       "      <td>295</td>\n",
       "      <td>['education', 'technology', 'animation', 'TED-...</td>\n",
       "      <td>2021-04-01T00:00:00.000+00:00</td>\n",
       "      <td>1617290223</td>\n",
       "      <td>In a pitch-black cave, bats can’t see much. Bu...</td>\n",
       "      <td>How LIGO discovered gravitational waves -- and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An honest history of an ancient and \"nasty\" word</td>\n",
       "      <td>Kate Lister</td>\n",
       "      <td>Sex historian</td>\n",
       "      <td>Kate Lister is a sex historian and lecturers a...</td>\n",
       "      <td>With candor and cunning, sex historian Kate Li...</td>\n",
       "      <td>TEDxUniversityofGlasgow</td>\n",
       "      <td>569477</td>\n",
       "      <td>1148</td>\n",
       "      <td>['sex', 'language', 'ancient world', 'history'...</td>\n",
       "      <td>2020-03-06T00:00:00.000+00:00</td>\n",
       "      <td>1617289565</td>\n",
       "      <td>First, a warning. As far as offensive words go...</td>\n",
       "      <td>Beautiful new words to describe obscure emotio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The electrical blueprints that orchestrate life</td>\n",
       "      <td>Michael Levin</td>\n",
       "      <td>Bioelectric explorer</td>\n",
       "      <td>Michael Levin's research could give rise to ad...</td>\n",
       "      <td>DNA isn't the only builder in the biological w...</td>\n",
       "      <td>TED2020</td>\n",
       "      <td>122682</td>\n",
       "      <td>1176</td>\n",
       "      <td>['biology', 'science', 'invention', 'robots', ...</td>\n",
       "      <td>2020-05-18T00:00:00.000+00:00</td>\n",
       "      <td>1617213773</td>\n",
       "      <td>Chris Anderson: Mike, welcome. It's good to se...</td>\n",
       "      <td>The next software revolution,Growing new organ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               talk             speaker  \\\n",
       "0  Can you outsmart the apples and oranges fallacy?       Elizabeth Cox   \n",
       "1           The exploitation of US college athletes          Tim Nevius   \n",
       "2                         How does ultrasound work?  Jacques Abramowicz   \n",
       "3  An honest history of an ancient and \"nasty\" word         Kate Lister   \n",
       "4   The electrical blueprints that orchestrate life       Michael Levin   \n",
       "\n",
       "             speaker_occ                                        speaker_bio  \\\n",
       "0                Unknown                                            Unknown   \n",
       "1  College sports lawyer  Tim Nevius is a leading sports lawyer and coll...   \n",
       "2                Unknown                                            Unknown   \n",
       "3          Sex historian  Kate Lister is a sex historian and lecturers a...   \n",
       "4   Bioelectric explorer  Michael Levin's research could give rise to ad...   \n",
       "\n",
       "                                           talk_desc                    event  \\\n",
       "0  It's 1997. The United States Senate has called...                   TED-Ed   \n",
       "1  Colleges and universities in the US make billi...               TEDxDayton   \n",
       "2  In a dark cave, bats can't see much. But even ...                   TED-Ed   \n",
       "3  With candor and cunning, sex historian Kate Li...  TEDxUniversityofGlasgow   \n",
       "4  DNA isn't the only builder in the biological w...                 TED2020    \n",
       "\n",
       "    views  duration                                               tags  \\\n",
       "0  119359       327  ['education', 'psychology', 'animation', 'TED-...   \n",
       "1  438573       611  ['sports', 'law', 'education', 'United States'...   \n",
       "2  140874       295  ['education', 'technology', 'animation', 'TED-...   \n",
       "3  569477      1148  ['sex', 'language', 'ancient world', 'history'...   \n",
       "4  122682      1176  ['biology', 'science', 'invention', 'robots', ...   \n",
       "\n",
       "                     recorded_at  published on  \\\n",
       "0  2021-04-05T00:00:00.000+00:00    1617636753   \n",
       "1  2020-11-10T00:00:00.000+00:00    1617634131   \n",
       "2  2021-04-01T00:00:00.000+00:00    1617290223   \n",
       "3  2020-03-06T00:00:00.000+00:00    1617289565   \n",
       "4  2020-05-18T00:00:00.000+00:00    1617213773   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  Baking apple pie? Discount orange warehouse ha...   \n",
       "1  In college sports, American universities are e...   \n",
       "2  In a pitch-black cave, bats can’t see much. Bu...   \n",
       "3  First, a warning. As far as offensive words go...   \n",
       "4  Chris Anderson: Mike, welcome. It's good to se...   \n",
       "\n",
       "                         most_similar_talks_unigrams  \n",
       "0  100 solutions to reverse global warming,How we...  \n",
       "1  Protecting the brain against concussion,A summ...  \n",
       "2  How LIGO discovered gravitational waves -- and...  \n",
       "3  Beautiful new words to describe obscure emotio...  \n",
       "4  The next software revolution,Growing new organ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c93e49cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ec9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360100a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a190b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00efd1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a541602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da43b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27d688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66e7d241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7abdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08bac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde220d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caaddf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "293b7906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vaishakkallampad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vaishakkallampad/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import gensim\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ca94a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing special characters and stop words from the text\n",
    "stop_words_l=stopwords.words('english')\n",
    "cleaned_df['talk_cleaned']=cleaned_df.talk.apply(lambda x: \" \".join(re.sub(r'[^a-zA-Z]',' ',w).lower() for w in x.split() if re.sub(r'[^a-zA-Z]',' ',w).lower() not in stop_words_l) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d172ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectoriser=TfidfVectorizer(max_features=64)\n",
    "tfidfvectoriser.fit(cleaned_df.talk_cleaned)\n",
    "tfidf_vectors=tfidfvectoriser.transform(cleaned_df.talk_cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "64909d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4016, 64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "16c7c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors=tfidf_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0a79eca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    6     1   329   319  5975   324  1668    44  1347   284  5976   485\n",
      "   275  3670    73     1    57 11300   724   373  5977  3288   112   139\n",
      "  2003   447  2991   159   725   400 11301  2141   135  1197   527  1099\n",
      "    74  2004  7657  4913    11   124    12   908   335   205    21  5978\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# tokenize and pad every document to make them of the same size\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(cleaned_df.desc_cleaned)\n",
    "tokenized_documents=tokenizer.texts_to_sequences(cleaned_df.desc_cleaned)\n",
    "tokenized_paded_documents=pad_sequences(tokenized_documents,maxlen=64,padding='post')\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "\n",
    "print (tokenized_paded_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7de3124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "W2V_PATH=\"GoogleNews-vectors-negative300.bin.gz\"\n",
    "model_w2v = gensim.models.KeyedVectors.load_word2vec_format(W2V_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4593e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating embedding matrix, every row is a vector representation from the vocabulary indexed by the tokenizer index. \n",
    "embedding_matrix=np.zeros((vocab_size,300))\n",
    "for word,i in tokenizer.word_index.items():\n",
    "    if word in model_w2v:\n",
    "        embedding_matrix[i]=model_w2v[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "77e99709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating document-word embeddings\n",
    "document_word_embeddings=np.zeros((len(tokenized_paded_documents),64,300))\n",
    "\n",
    "for i in range(len(tokenized_paded_documents)):\n",
    "    for j in range(len(tokenized_paded_documents[0])):\n",
    "        document_word_embeddings[i][j]=embedding_matrix[tokenized_paded_documents[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fae69aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4016, 64, 300)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_word_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6284cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf vectors do not keep the original sequence of words, converting them into actual word sequences from the documents\n",
    "\n",
    "document_embeddings=np.zeros((len(tokenized_paded_documents),300))\n",
    "words=tfidfvectoriser.get_feature_names_out()\n",
    "\n",
    "for i in range(len(document_word_embeddings)):\n",
    "    for j in range(len(words)):\n",
    "        document_embeddings[i]+=embedding_matrix[tokenizer.word_index[words[j]]]*tfidf_vectors[i][j]\n",
    "        \n",
    "    document_embeddings=document_embeddings/np.sum(tfidf_vectors,axis=1).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eac991aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 0.02990723,  0.05639648,  0.0037384 , ..., -0.02416992,\n",
       "         0.01086426, -0.14746094],\n",
       "       [-0.07568359,  0.03369141, -0.06494141, ...,  0.01202393,\n",
       "         0.13574219, -0.09130859],\n",
       "       ...,\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [ 0.17871094,  0.32617188, -0.11865234, ...,  0.41796875,\n",
       "         0.31445312,  0.06542969]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6d412530",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-2ef15a885bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim_word2vec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msim_word2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         X = Y = check_array(\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "sim_word2vec=cosine_similarity(document_embeddings)\n",
    "sim_word2vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befab28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de90396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "086cbebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4016, 256)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "59adb78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4016, 300)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1e329994",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-eeb2375fd23e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpairwise_similarities\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         X = Y = check_array(\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "pairwise_similarities=cosine_similarity(document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9f27b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['most_similar_talks_w2v']=[get_similar_articles(x) for x in sim_word2vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c9e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
